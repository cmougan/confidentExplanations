{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d7ce084",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'attributes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/cmougan/Desktop/confidentExplanations/test shapley selection function.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cmougan/Desktop/confidentExplanations/test%20shapley%20selection%20function.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlightgbm\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mlgb\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cmougan/Desktop/confidentExplanations/test%20shapley%20selection%20function.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/cmougan/Desktop/confidentExplanations/test%20shapley%20selection%20function.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mattributes\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cmougan/Desktop/confidentExplanations/test%20shapley%20selection%20function.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#here we import X features of dataset\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cmougan/Desktop/confidentExplanations/test%20shapley%20selection%20function.ipynb#W0sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m atts \u001b[39m=\u001b[39m atts_giveme\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'attributes'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from attributes import *\n",
    "\n",
    "#here we import X features of dataset\n",
    "atts = atts_giveme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c67754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we read datasets\n",
    "df = pd.read_pickle('GiveMe_train.pkl')\n",
    "df_test = pd.read_pickle('GiveMe_test.pkl')\n",
    "df_test['age'] = df_test['age'].astype(float)\n",
    "df_test = df_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e161eac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LGBMClassifier'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb.LGBMClassifier(random_state=42, n_jobs=2).__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0362e943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we split train and hold set\n",
    "df_train, df_hold = train_test_split(df, stratify=df['TARGET'], random_state=42, test_size=.1)\n",
    "df_train = df_train.reset_index()\n",
    "df_hold = df_hold.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "426d1bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(n_jobs=2, random_state=42)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here we train the first classifier f over training set \n",
    "clf_base = lgb.LGBMClassifier(random_state=42, n_jobs=2)\n",
    "clf_base.fit(df_train[atts], df_train['TARGET'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eee9078",
   "metadata": {},
   "source": [
    "here we compute scores and errors as $|y-s(X)|$, where $s(X) \\sim P(y=1|X)$ over holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10e3ee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hold['scores'] = clf_base.predict_proba(df_hold[atts])[:,1]\n",
    "df_hold['err'] = np.fabs(df_hold['TARGET']-df_hold['scores'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392d51ef",
   "metadata": {},
   "source": [
    "here we plot errors distrbution over holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16e966a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([9084.,  814.,  301.,  216.,  141.,  128.,  109.,   93.,  121.,\n",
       "         243.]),\n",
       " array([0.00143706, 0.10107543, 0.2007138 , 0.30035218, 0.39999055,\n",
       "        0.49962892, 0.5992673 , 0.69890567, 0.79854404, 0.89818242,\n",
       "        0.99782079]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAO7UlEQVR4nO3dcaydd13H8ffHls0BTjp3t8zbYYupwLZIYHVWUIJMszKMnQlLGoU1ZEnjnIjGRDr+kD9Mk5EYA4tupBm4LhKaZiyuikOX4kTD2LiDQenqXGXYXVfXCypMTIbdvv5xnj9O2tPe567nnsvp7/1KTs45v/M85/x+afO+T597zmmqCklSG35opScgSZocoy9JDTH6ktQQoy9JDTH6ktSQ1Ss9gcVceOGFtW7dupWehiRNlUcfffRbVTVz4vgPfPTXrVvH3NzcSk9DkqZKkn8bNe7pHUlqiNGXpIYYfUlqiNGXpIYYfUlqiNGXpIYYfUlqiNGXpIYYfUlqyA/8J3LPxLodn1mR1/3mre9ckdeVpMV4pC9JDTH6ktQQoy9JDTH6ktQQoy9JDTH6ktQQoy9JDTH6ktQQoy9JDTH6ktQQoy9JDTH6ktQQoy9JDTH6ktQQoy9JDTH6ktQQoy9JDTH6ktQQoy9JDTH6ktSQXtFP8ntJDib5epJPJfnhJBckeSDJk931mqHtb0lyOMkTSa4ZGr8yyYHusduSZDkWJUkabdHoJ5kFfgfYWFVXAKuArcAOYH9VbQD2d/dJcln3+OXAZuD2JKu6p7sD2A5s6C6bx7oaSdJp9T29sxo4L8lq4OXAM8AWYHf3+G7guu72FmBPVT1fVU8Bh4GrklwCnF9VD1VVAXcP7SNJmoBFo19V/w78MXAEOAp8p6r+Dri4qo522xwFLup2mQWeHnqK+W5strt94vhJkmxPMpdkbmFhYWkrkiSdUp/TO2sYHL2vB34ceEWSd59ulxFjdZrxkwerdlXVxqraODMzs9gUJUk99Tm980vAU1W1UFX/B9wLvBl4tjtlQ3d9rNt+Hrh0aP+1DE4HzXe3TxyXJE1In+gfATYleXn3bpurgUPAPmBbt8024L7u9j5ga5Jzk6xn8AvbR7pTQM8l2dQ9zw1D+0iSJmD1YhtU1cNJ7gG+DBwHvgLsAl4J7E1yI4MfDNd32x9Mshd4vNv+5qp6oXu6m4C7gPOA+7uLJGlCFo0+QFV9CPjQCcPPMzjqH7X9TmDniPE54IolzlGSNCZ+IleSGmL0JakhRl+SGmL0JakhRl+SGmL0JakhRl+SGmL0JakhRl+SGmL0JakhRl+SGmL0JakhRl+SGmL0JakhRl+SGmL0JakhRl+SGmL0JakhRl+SGmL0JakhRl+SGmL0JakhRl+SGmL0JakhRl+SGmL0JakhRl+SGmL0JakhRl+SGmL0JakhRl+SGmL0JakhRl+SGmL0JakhRl+SGmL0JakhRl+SGtIr+kleleSeJP+c5FCSn0tyQZIHkjzZXa8Z2v6WJIeTPJHkmqHxK5Mc6B67LUmWY1GSpNH6Hul/FPhsVb0OeANwCNgB7K+qDcD+7j5JLgO2ApcDm4Hbk6zqnucOYDuwobtsHtM6JEk9LBr9JOcDbwU+DlBV36+q/wa2ALu7zXYD13W3twB7qur5qnoKOAxcleQS4PyqeqiqCrh7aB9J0gT0OdJ/DbAA/HmSryS5M8krgIur6ihAd31Rt/0s8PTQ/vPd2Gx3+8TxkyTZnmQuydzCwsKSFiRJOrU+0V8NvAm4o6reCHyP7lTOKYw6T1+nGT95sGpXVW2sqo0zMzM9pihJ6qNP9OeB+ap6uLt/D4MfAs92p2zoro8NbX/p0P5rgWe68bUjxiVJE7Jo9KvqP4Cnk7y2G7oaeBzYB2zrxrYB93W39wFbk5ybZD2DX9g+0p0Cei7Jpu5dOzcM7SNJmoDVPbd7H/DJJOcA3wDey+AHxt4kNwJHgOsBqupgkr0MfjAcB26uqhe657kJuAs4D7i/u0iSJqRX9KvqMWDjiIeuPsX2O4GdI8bngCuWMD9J0hj5iVxJaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SG9I5+klVJvpLkr7v7FyR5IMmT3fWaoW1vSXI4yRNJrhkavzLJge6x25JkvMuRJJ3OUo703w8cGrq/A9hfVRuA/d19klwGbAUuBzYDtydZ1e1zB7Ad2NBdNp/R7CVJS9Ir+knWAu8E7hwa3gLs7m7vBq4bGt9TVc9X1VPAYeCqJJcA51fVQ1VVwN1D+0iSJqDvkf5HgD8AXhwau7iqjgJ01xd147PA00PbzXdjs93tE8clSROyaPST/ApwrKoe7fmco87T12nGR73m9iRzSeYWFhZ6vqwkaTF9jvTfAvxqkm8Ce4C3J/kL4NnulA3d9bFu+3ng0qH91wLPdONrR4yfpKp2VdXGqto4MzOzhOVIkk5n0ehX1S1Vtbaq1jH4Be3nqurdwD5gW7fZNuC+7vY+YGuSc5OsZ/AL20e6U0DPJdnUvWvnhqF9JEkTsPoM9r0V2JvkRuAIcD1AVR1Mshd4HDgO3FxVL3T73ATcBZwH3N9dJEkTsqToV9WDwIPd7W8DV59iu53AzhHjc8AVS52kJGk8/ESuJDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDVk0egnuTTJ3yc5lORgkvd34xckeSDJk931mqF9bklyOMkTSa4ZGr8yyYHusduSZHmWJUkapc+R/nHg96vq9cAm4OYklwE7gP1VtQHY392ne2wrcDmwGbg9yaruue4AtgMbusvmMa5FkrSIRaNfVUer6svd7eeAQ8AssAXY3W22G7iuu70F2FNVz1fVU8Bh4KoklwDnV9VDVVXA3UP7SJImYEnn9JOsA94IPAxcXFVHYfCDAbio22wWeHpot/lubLa7feL4qNfZnmQuydzCwsJSpihJOo3e0U/ySuDTwO9W1XdPt+mIsTrN+MmDVbuqamNVbZyZmek7RUnSInpFP8nLGAT/k1V1bzf8bHfKhu76WDc+D1w6tPta4JlufO2IcUnShPR5906AjwOHqupPhh7aB2zrbm8D7hsa35rk3CTrGfzC9pHuFNBzSTZ1z3nD0D6SpAlY3WObtwDvAQ4keawb+yBwK7A3yY3AEeB6gKo6mGQv8DiDd/7cXFUvdPvdBNwFnAfc310kSROyaPSr6p8YfT4e4OpT7LMT2DlifA64YikTlCSNj5/IlaSGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGGH1JaojRl6SGrF7pCZyN1u34zIq99jdvfeeKvbakH3we6UtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ4y+JDXE6EtSQ/zunbPMSn3vj9/5I00Hoy9Jp3G2HUgZfY2F3ywqTQfP6UtSQyZ+pJ9kM/BRYBVwZ1XdOuk56Oyykv/KaM1K/avKP+PxmWj0k6wC/gz4ZWAe+FKSfVX1+CTnIemlMb7Tb9Knd64CDlfVN6rq+8AeYMuE5yBJzZr06Z1Z4Omh+/PAz564UZLtwPbu7v8keeIlvNaFwLdewn7TrsV1u+Y2NLXmfBg4szX/xKjBSUc/I8bqpIGqXcCuM3qhZK6qNp7Jc0yjFtftmtvgmsdj0qd35oFLh+6vBZ6Z8BwkqVmTjv6XgA1J1ic5B9gK7JvwHCSpWRM9vVNVx5P8NvC3DN6y+YmqOrhML3dGp4emWIvrds1tcM1jkKqTTqlLks5SfiJXkhpi9CWpIVMf/SSbkzyR5HCSHSMeT5Lbuse/luRNKzHPceqx5t/o1vq1JF9I8oaVmOc4Lbbmoe1+JskLSd41yfkthz5rTvK2JI8lOZjkHyY9x3Hr8Xf7R5P8VZKvdmt+70rMc5ySfCLJsSRfP8Xj421YVU3thcEvg/8VeA1wDvBV4LITtrkWuJ/BZwQ2AQ+v9LwnsOY3A2u62+9oYc1D230O+BvgXSs97wn8Ob8KeBx4dXf/opWe9wTW/EHgw93tGeA/gXNWeu5nuO63Am8Cvn6Kx8fasGk/0u/ztQ5bgLtr4IvAq5JcMumJjtGia66qL1TVf3V3v8jg8xDTrO/Xd7wP+DRwbJKTWyZ91vzrwL1VdQSgqqZ93X3WXMCPJAnwSgbRPz7ZaY5XVX2ewTpOZawNm/boj/pah9mXsM00Wep6bmRwlDDNFl1zklng14CPTXBey6nPn/NPAWuSPJjk0SQ3TGx2y6PPmv8UeD2DD3UeAN5fVS9OZnorZqwNm/b/RKXP1zr0+uqHKdJ7PUl+kUH0f35ZZ7T8+qz5I8AHquqFwUHg1Ouz5tXAlcDVwHnAQ0m+WFX/styTWyZ91nwN8BjwduAngQeS/GNVfXeZ57aSxtqwaY9+n691ONu++qHXepL8NHAn8I6q+vaE5rZc+qx5I7CnC/6FwLVJjlfVX05khuPX9+/2t6rqe8D3knweeAMwrdHvs+b3ArfW4GT34SRPAa8DHpnMFFfEWBs27ad3+nytwz7ghu434JuA71TV0UlPdIwWXXOSVwP3Au+Z4qO+YYuuuarWV9W6qloH3AP81hQHH/r93b4P+IUkq5O8nME31h6a8DzHqc+ajzD4lw1JLgZeC3xjorOcvLE2bKqP9OsUX+uQ5De7xz/G4J0c1wKHgf9lcKQwtXqu+Q+BHwNu7458j9cUfzthzzWfVfqsuaoOJfks8DXgRQb/E93It/1Ng55/zn8E3JXkAIPTHh+oqqn+uuUknwLeBlyYZB74EPAyWJ6G+TUMktSQaT+9I0laAqMvSQ0x+pLUEKMvSQ0x+pLUEKMvSQ0x+pLUkP8Hgv8QJl8b7KYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(df_hold['err'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df02e15",
   "metadata": {},
   "source": [
    "here we compute shapley values $\\phi(X_{hold})$ over holdout set\n",
    "\n",
    ">If you want to get more explanations for your modelâ€™s predictions using SHAP values, like SHAP interaction values, you can install the shap package (https://github.com/slundberg/shap). Note that unlike the shap package, with pred_contrib we return a matrix with an extra column, where the last column is the expected value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bffbf34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['shap_{}'.format(col) for col in df_hold[atts].columns]\n",
    "shaps = pd.DataFrame(clf_base.predict(df_hold[atts], pred_contrib=True)[:,:-1], columns = cols)\n",
    "shaps['err'] = df_hold['err'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286bb78c",
   "metadata": {},
   "source": [
    "here we define our low-high error for acceptance (if error below a certain threshold depending on target coverage we accept the instance, otherwise reject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5819e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile = .8\n",
    "theta = np.quantile(shaps['err'], quantile)\n",
    "shaps['ACCEPTED'] = np.where(shaps['err']<theta, 1, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0727dee",
   "metadata": {},
   "source": [
    "here we build a selector $g:\\phi(X) \\to \\{0,1\\}$, which learns when to reject from explanation space;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b2a2c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(random_state=42)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = lgb.LGBMClassifier(random_state=42)\n",
    "g.fit(shaps[cols], shaps['ACCEPTED'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dee8158",
   "metadata": {},
   "source": [
    "here we test over a test set whether selected instances according to the selector g increase performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1eaffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "shaps_test = pd.DataFrame(clf_base.predict(df_test[atts], pred_contrib=True)[:,:-1], columns = cols)\n",
    "scores = clf_base.predict_proba(df_test[atts])[:, 1]\n",
    "# shaps_test['err'] = np.fabs(df_test['TARGET']-scores)\n",
    "# shaps_test['ACCEPTED'] = np.where(shaps_test['err']<theta, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cd685d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc auc score full sample\n",
      "0.8660279853698326\n",
      "roc auc score selected\n",
      "0.7539643775004781\n",
      "accuracy full sample\n",
      "0.93696\n",
      "accuracy selected\n",
      "0.9750990195441854\n",
      "coverage selected\n",
      "0.8213866666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "preds = clf_base.predict(df_test[atts])\n",
    "selected = g.predict(shaps_test[cols]).astype(bool)\n",
    "print(\"roc auc score full sample\")\n",
    "print(roc_auc_score(df_test['TARGET'], scores))\n",
    "print(\"roc auc score selected\")\n",
    "print(roc_auc_score(df_test[selected]['TARGET'], scores[selected]))\n",
    "print(\"accuracy full sample\")\n",
    "print(accuracy_score(df_test['TARGET'], preds))\n",
    "print(\"accuracy selected\")\n",
    "print(accuracy_score(df_test[selected]['TARGET'], preds[selected]))\n",
    "print(\"coverage selected\")\n",
    "print(selected.sum()/len(selected))\n",
    "# roc_auc_score(shaps_test['ACCEPTED'], g.predict_proba(shaps_test[cols])[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f100c5",
   "metadata": {},
   "source": [
    "Testing over multiple coverages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fda0ce1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(shaps_train, shaps_test, df_test, atts, clf_base,  list_coverages):\n",
    "    for quantile in list_coverages:\n",
    "        theta = np.quantile(shaps['err'], quantile)\n",
    "        print(\"target coverage is {}\\n\\n\\n\".format(quantile))\n",
    "        shaps_train['ACCEPTED'] = np.where(shaps_train['err']<theta, 1, 0)\n",
    "#         if (abs(1-quantile)<=.1):\n",
    "#             g = lgb.LGBMClassifier(random_state=42, is_unbalance=True)\n",
    "#         else:\n",
    "        g = lgb.LGBMClassifier(random_state=42)\n",
    "        g.fit(shaps[cols], shaps['ACCEPTED'])\n",
    "        shaps_test = pd.DataFrame(clf_base.predict(df_test[atts], pred_contrib=True)[:,:-1], columns = cols)\n",
    "        scores = clf_base.predict_proba(df_test[atts])[:, 1]\n",
    "        preds = clf_base.predict(df_test[atts])\n",
    "        selected = g.predict(shaps_test[cols]).astype(bool)\n",
    "        print(\"roc auc score full sample\")\n",
    "        print(roc_auc_score(df_test['TARGET'], scores))\n",
    "        print(\"roc auc score selected\")\n",
    "        print(roc_auc_score(df_test[selected]['TARGET'], scores[selected]))\n",
    "        print(\"accuracy full sample\")\n",
    "        print(accuracy_score(df_test['TARGET'], preds))\n",
    "        print(\"accuracy selected\")\n",
    "        print(accuracy_score(df_test[selected]['TARGET'], preds[selected]))\n",
    "        print(\"coverage selected\")\n",
    "        print(selected.sum()/len(selected))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a811d572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target coverage is 0.99\n",
      "\n",
      "\n",
      "\n",
      "roc auc score full sample\n",
      "0.8660279853698326\n",
      "roc auc score selected\n",
      "0.8660313774880833\n",
      "accuracy full sample\n",
      "0.93696\n",
      "accuracy selected\n",
      "0.9369448667680244\n",
      "coverage selected\n",
      "0.99976\n",
      "\n",
      "\n",
      "target coverage is 0.95\n",
      "\n",
      "\n",
      "\n",
      "roc auc score full sample\n",
      "0.8660279853698326\n",
      "roc auc score selected\n",
      "0.8655420869678144\n",
      "accuracy full sample\n",
      "0.93696\n",
      "accuracy selected\n",
      "0.9378446383639382\n",
      "coverage selected\n",
      "0.9962133333333333\n",
      "\n",
      "\n",
      "target coverage is 0.9\n",
      "\n",
      "\n",
      "\n",
      "roc auc score full sample\n",
      "0.8660279853698326\n",
      "roc auc score selected\n",
      "0.8043184495080592\n",
      "accuracy full sample\n",
      "0.93696\n",
      "accuracy selected\n",
      "0.9604545715433622\n",
      "coverage selected\n",
      "0.9292266666666666\n",
      "\n",
      "\n",
      "target coverage is 0.85\n",
      "\n",
      "\n",
      "\n",
      "roc auc score full sample\n",
      "0.8660279853698326\n",
      "roc auc score selected\n",
      "0.7645723660371213\n",
      "accuracy full sample\n",
      "0.93696\n",
      "accuracy selected\n",
      "0.9705730354157167\n",
      "coverage selected\n",
      "0.8772\n",
      "\n",
      "\n",
      "target coverage is 0.8\n",
      "\n",
      "\n",
      "\n",
      "roc auc score full sample\n",
      "0.8660279853698326\n",
      "roc auc score selected\n",
      "0.7539643775004781\n",
      "accuracy full sample\n",
      "0.93696\n",
      "accuracy selected\n",
      "0.9750990195441854\n",
      "coverage selected\n",
      "0.8213866666666667\n",
      "\n",
      "\n",
      "target coverage is 0.75\n",
      "\n",
      "\n",
      "\n",
      "roc auc score full sample\n",
      "0.8660279853698326\n",
      "roc auc score selected\n",
      "0.7332481646655231\n",
      "accuracy full sample\n",
      "0.93696\n",
      "accuracy selected\n",
      "0.9796920718963356\n",
      "coverage selected\n",
      "0.7655466666666667\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_coverages = [ .99, .95, .9, .85, .8, .75]\n",
    "test(shaps, shaps_test, df_test, atts, clf_base,  list_coverages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('explanationShift')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "97fe26bcbf28fc453b2946b997c23025578b6596c26e056eb0f37c1d31a215af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
